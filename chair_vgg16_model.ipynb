{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPmE7GLitqv+45DUd30ZcZ9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MuhammadBasilKhan/chair-image-detection/blob/main/chair_vgg16_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03M2Dh_2KnHR",
        "outputId": "49b229c7-bc49-4a22-be84-787668e0f08a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sihZvnu9KtTi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categories=['Comedor','Gamer','Mesedoras','Taburete','Terraza']\n"
      ],
      "metadata": {
        "id": "xLW35YfyLFr_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir='/content/drive/MyDrive/drive/chair data/training'"
      ],
      "metadata": {
        "id": "OB7tdkkfM0Ry"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2"
      ],
      "metadata": {
        "id": "gYuZF37_Lzzn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imgsize=224\n",
        "data=[]\n",
        "for category in categories:\n",
        "  folder=os.path.join(dir,category)\n",
        "  label=categories.index(category)\n",
        "  for img in os.listdir(folder):\n",
        "    img_path=os.path.join(folder,img)\n",
        "    img_arr=cv2.imread(img_path)\n",
        "    img_arr=cv2.resize(img_arr,(imgsize,imgsize))\n",
        "    data.append([img_arr,label])"
      ],
      "metadata": {
        "id": "r_XDr7-NLlfb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tumz7m9oMa_t",
        "outputId": "3c9ce6c2-88a9-455c-8e0b-ea6d9ad9916e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2500"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random"
      ],
      "metadata": {
        "id": "8DuNHh68QOw8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.shuffle(data)"
      ],
      "metadata": {
        "id": "PTo_GWx2QTF3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=[]\n",
        "y=[]\n",
        "for features,label in data:\n",
        "  x.append(features)\n",
        "  y.append(label)\n",
        "  len(x)\n",
        "  len(y)"
      ],
      "metadata": {
        "id": "IRoOZn75QWcc"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "J086StJBQkYL"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=np.array(x)\n",
        "Y=np.array(y)"
      ],
      "metadata": {
        "id": "ytZWueDoQnLm"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUdEBVq-QrwK",
        "outputId": "5e686217-dec5-46e3-a611-854bad3e9fae"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2500, 224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-Yn3O3TQw_W",
        "outputId": "0bce1f02-a7db-4a01-e4f9-ecc7703f9fed"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2500,)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2)"
      ],
      "metadata": {
        "id": "YpyX5FJSQyKR"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255."
      ],
      "metadata": {
        "id": "lc6Z5ZvZV-L1"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gc1aGiRSRIlp",
        "outputId": "628a2f26-8dcf-42cf-9914-e3edb8af7ca1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFASoCgSRR_k",
        "outputId": "af21a46f-1928-434b-f3f9-fad130a1e627"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(500, 224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "vgg=VGG16()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCz_LTU8RUQJ",
        "outputId": "fad5f26f-e812-4f35-9fd4-8635495a2177"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467096/553467096 [==============================] - 11s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vgg = VGG16(include_top=False, input_shape=(imgsize, imgsize, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_piX7N0WMtu",
        "outputId": "5cae660d-91f2-4441-d74f-c934e8da5c50"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import Sequential\n",
        "model=Sequential()\n"
      ],
      "metadata": {
        "id": "JBR3TLBrR7xl"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Dense\n",
        "from keras.layers import Dense, Flatten"
      ],
      "metadata": {
        "id": "_nK1Z8qwSmJc"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in vgg.layers:\n",
        "    model.add(layer)"
      ],
      "metadata": {
        "id": "MjBYD1tBWfr8"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Flatten())\n",
        "model.add(Dense(len(categories),activation='softmax'))"
      ],
      "metadata": {
        "id": "Q0iYuRArSrsZ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvwGS_K7S2EX",
        "outputId": "5399c6ab-f97f-48b7-c075-7142cd6d7a92"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 5)                 125445    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14840133 (56.61 MB)\n",
            "Trainable params: 14840133 (56.61 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model.layers[:-2]:  # Exclude the newly added dense layer\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "6RuaJcWqWoYM"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "x5mO0fLkS4JS"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train,Y_train,epochs=10,validation_data=(X_test,Y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ig3LmxvvTMbl",
        "outputId": "e426b29c-36f5-47da-eac8-ac4034837ca4"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "63/63 [==============================] - 28s 298ms/step - loss: 0.3374 - accuracy: 0.8765 - val_loss: 0.2363 - val_accuracy: 0.9040\n",
            "Epoch 2/10\n",
            "63/63 [==============================] - 10s 158ms/step - loss: 0.0639 - accuracy: 0.9800 - val_loss: 0.1697 - val_accuracy: 0.9440\n",
            "Epoch 3/10\n",
            "63/63 [==============================] - 10s 157ms/step - loss: 0.0290 - accuracy: 0.9920 - val_loss: 0.1201 - val_accuracy: 0.9540\n",
            "Epoch 4/10\n",
            "63/63 [==============================] - 9s 147ms/step - loss: 0.0159 - accuracy: 0.9990 - val_loss: 0.1199 - val_accuracy: 0.9540\n",
            "Epoch 5/10\n",
            "63/63 [==============================] - 10s 159ms/step - loss: 0.0117 - accuracy: 0.9995 - val_loss: 0.1176 - val_accuracy: 0.9540\n",
            "Epoch 6/10\n",
            "63/63 [==============================] - 10s 159ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.1036 - val_accuracy: 0.9680\n",
            "Epoch 7/10\n",
            "63/63 [==============================] - 10s 159ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.1030 - val_accuracy: 0.9660\n",
            "Epoch 8/10\n",
            "63/63 [==============================] - 10s 161ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.1050 - val_accuracy: 0.9600\n",
            "Epoch 9/10\n",
            "63/63 [==============================] - 9s 149ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1071 - val_accuracy: 0.9580\n",
            "Epoch 10/10\n",
            "63/63 [==============================] - 10s 160ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1044 - val_accuracy: 0.9560\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x79c7e8718b80>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hezTjGlQTdmi",
        "outputId": "8bc3fdad-a3c0-46c1-caf8-9e3951e92fbf"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 2s 116ms/step - loss: 0.1044 - accuracy: 0.9560\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.10440903902053833, 0.9559999704360962]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('chairvgg16.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJ2UiQ-pbBs7",
        "outputId": "213ff9ce-e560-4c31-a69d-5a76a0551a23"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Define the categories\n",
        "categories = ['Comedor', 'Gamer', 'Mesedoras', 'Taburete', 'Terraza']\n",
        "\n",
        "# Load the trained model (assuming it's already trained as per the previous code)\n",
        "# If you saved the model, load it using the following lines:\n",
        "# from keras.models import load_model\n",
        "# model = load_model('path_to_your_model.h5')\n",
        "\n",
        "def preprocess_image(image_path, imgsize=224):\n",
        "    \"\"\"Preprocess the image to the required input shape for the model.\"\"\"\n",
        "    img_arr = cv2.imread(image_path)\n",
        "    img_arr = cv2.resize(img_arr, (imgsize, imgsize))\n",
        "    img_arr = img_arr / 255.0  # Normalize the image\n",
        "    img_arr = np.expand_dims(img_arr, axis=0)  # Expand dimensions to match the model input\n",
        "    return img_arr\n",
        "\n",
        "def predict_category(image_path, model, categories):\n",
        "    \"\"\"Predict the category of the image.\"\"\"\n",
        "    img_arr = preprocess_image(image_path)\n",
        "    prediction = model.predict(img_arr)\n",
        "    predicted_index = np.argmax(prediction, axis=1)[0]\n",
        "    return categories[predicted_index]\n",
        "\n",
        "# Example usage:\n",
        "image_path = '/content/drive/MyDrive/drive/chair data/training/Mesedoras/1645818166920.jpeg'  # Replace with the path to your image\n",
        "predicted_category = predict_category(image_path, model, categories)\n",
        "print(f\"The predicted category is: {predicted_category}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cnBncMabMih",
        "outputId": "15fa1ec8-7f69-49bf-ff56-de32b9edcac6"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 27ms/step\n",
            "The predicted category is: Mesedoras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tphD0OxXb20P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}